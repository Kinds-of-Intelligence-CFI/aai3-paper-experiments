{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO Evaluation Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from animalai.envs.environment import AnimalAIEnvironment\n",
    "from mlagents_envs.envs.unity_gym_env import UnityToGymWrapper\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from aaisrc.aaiyaml import find_yaml_files\n",
    "from aaisrc.aaiyaml import yaml_combinor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ppo(env_path : str, configuration_file : str, model_path : str, save_path : str, watch : bool = False, num_runs : int = 100, verbose : bool = True):\n",
    "    episode_rewards = []\n",
    "\n",
    "    model = PPO.load(model_path)\n",
    "\n",
    "    port = 5005 + random.randint(\n",
    "    0, 10000\n",
    "    )  # use a random port to avoid problems if a previous version exits slowly\n",
    "\n",
    "    aai_env = AnimalAIEnvironment(\n",
    "        inference=watch,\n",
    "        seed = 2023,\n",
    "        file_name=env_path,\n",
    "        arenas_configurations=configuration_file,\n",
    "        play=False,\n",
    "        base_port=port,\n",
    "        useCamera=False,\n",
    "        useRayCasts=True,\n",
    "        raysPerSide=15,\n",
    "        rayMaxDegrees = 30,\n",
    "        no_graphics=(not watch),\n",
    "        timescale = 1\n",
    "        )\n",
    "    \n",
    "    env = UnityToGymWrapper(aai_env, uint8_visual=False, allow_multiple_obs=True, flatten_branched=True) \n",
    "\n",
    "    obs = env.reset()\n",
    " \n",
    "    \n",
    "    for _episode in range(num_runs): \n",
    "        if verbose:\n",
    "            print(f\"Running episode {_episode+1} of {num_runs}.\")   \n",
    "        done = False\n",
    "        episodeReward = 0\n",
    "        while not done:\n",
    "            action, _state = model.predict(obs[0], deterministic=False)\n",
    "            obs, reward, done, info = env.step(action.item())\n",
    "            episodeReward += reward\n",
    "            env.render()\n",
    "            if done:\n",
    "                obs = env.reset()\n",
    "                if verbose:\n",
    "                    print(episodeReward)\n",
    "                episode_rewards.append(episodeReward)\n",
    "                break #to be sure\n",
    "    \n",
    "    env.close()\n",
    "\n",
    "    results_dataframe = pd.DataFrame({\"EpisodeNumber\" : [x for x in range(num_runs)],\n",
    "                                     \"FinalReward\" : episode_rewards})\n",
    "    \n",
    "    results_dataframe.to_csv(save_path,\n",
    "                            index = False)\n",
    "\n",
    "    return results_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ppo_directory(env_path : str, model_path : str, configuration_folder : str, tmp_file_location : str, save_path_csv : str, watch : bool = False, seed : int = 2023, batch_size: int = 50, port_base : int = 6600):\n",
    "    \n",
    "    model = PPO.load(model_path)\n",
    "    \n",
    "    yaml_index = 0\n",
    "\n",
    "    port = port_base + yaml_index\n",
    "        \n",
    "    batch_counter = 0\n",
    "\n",
    "    paths, names = find_yaml_files(configuration_folder)\n",
    "\n",
    "    \n",
    "    for yaml_index in range(0, len(paths), batch_size):\n",
    "        if (yaml_index + batch_size) > len(paths) or batch_size > len(paths):\n",
    "            upper_bound = len(paths)\n",
    "        else:\n",
    "            upper_bound = ((yaml_index + batch_size))\n",
    "        \n",
    "        print(f\"Running inferences on batch {batch_counter + 1} of {batch_size} files of total {len(paths)}. {len(paths) - (batch_size * (batch_counter + 1))} instances to go.\")\n",
    "\n",
    "        batch_files = paths[yaml_index:upper_bound]\n",
    "\n",
    "        batch_file_names = names[yaml_index:upper_bound]\n",
    "\n",
    "        batch_temp_file_name = f\"TempConfig_PPO_{seed}_{yaml_index}.yml\"\n",
    "\n",
    "        config_file_path = yaml_combinor(file_list = batch_files, temp_file_location=tmp_file_location, stored_file_name = batch_temp_file_name)\n",
    "    \n",
    "        aai_env = AnimalAIEnvironment( \n",
    "            inference=watch, #Set true when watching the agent\n",
    "            seed = seed,\n",
    "            worker_id=random.randint(0, 65500),\n",
    "            file_name=env_path,\n",
    "            arenas_configurations=config_file_path,\n",
    "            base_port=port,\n",
    "            useCamera=False,\n",
    "            useRayCasts=True,\n",
    "            raysPerSide = 15,\n",
    "            rayMaxDegrees = 30,\n",
    "            no_graphics=(not watch),\n",
    "            timescale=1\n",
    "        )\n",
    "\n",
    "        env = UnityToGymWrapper(aai_env, uint8_visual=False, allow_multiple_obs=True, flatten_branched=True)\n",
    "\n",
    "    \n",
    "\n",
    "        random.seed(seed)\n",
    "\n",
    "        for _episode in range(batch_size): \n",
    "            print(f\"Running episode {_episode+1} of {batch_size}: {batch_file_names[_episode]}\") \n",
    "        \n",
    "            obs = env.reset()\n",
    "        \n",
    "            done = False\n",
    "            episodeReward = 0\n",
    "\n",
    "            while not done:\n",
    "\n",
    "                action, _state = model.predict(obs[0], deterministic=False)\n",
    "                obs, reward, done, info = env.step(action.item())\n",
    "                episodeReward += reward\n",
    "                env.render()\n",
    "                \n",
    "            file_exists = os.path.isfile(save_path_csv)\n",
    "            with open(save_path_csv, 'a' if file_exists else 'w', newline='') as csv_file:\n",
    "                csv_write = csv.writer(csv_file)\n",
    "                if not file_exists:\n",
    "                    csv_write.writerow(['episode', 'finalReward'])\n",
    "\n",
    "                csv_write.writerow([str(names[yaml_index+_episode]), str(episodeReward)])\n",
    "                print(f\"Writing episode score {episodeReward} for episode {names[yaml_index+_episode]} to {save_path_csv}\")\n",
    "        env.close()\n",
    "        os.remove(config_file_path)\n",
    "        batch_counter += 1\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_dataframe = evaluate_ppo(env_path = \"../env/AnimalAI.exe\",\n",
    "                         configuration_file = \"../configs/buttonPressTask/buttonPressGreen.yml\",\n",
    "                         model_path = \"../modelsaves/buttonPressTask/model_2000000.zip\",\n",
    "                         save_path = \"../analysis/data/buttonPress/PPORaycast100Button.csv\",\n",
    "                         watch=False,\n",
    "                         num_runs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foraging_dataframe = evaluate_ppo(env_path = \"../env/AnimalAI.exe\",\n",
    "                         configuration_file = \"../configs/foragingTask/foragingTaskSpawnerTree.yml\",\n",
    "                         model_path = \"../modelsaves/foragingTask/model_1000000.zip\",\n",
    "                         save_path = \"../analysis/data/foraging/PPORaycast100Foraging.csv\",\n",
    "                         watch=False,\n",
    "                         num_runs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = False\n",
    "pt = 1000\n",
    "random.seed(2050)\n",
    "\n",
    "while not eval:\n",
    "    try:\n",
    "        eval = evaluate_ppo(env_path = \"../env/AnimalAI.exe\",\n",
    "                    model_path = \"../modelsaves/competitionAAITestbed/model_2000000.zip\",\n",
    "                    configuration_folder = \"../configs/competition\",\n",
    "                    tmp_file_location = \"../..\",\n",
    "                    save_path_csv=\"../analysis/data/competitionAAITestbed/PPOAAITestbed2050.csv\",\n",
    "                    seed = random.randint(1000, 10000),\n",
    "                    port_base = pt,\n",
    "                    batch_size = 1,\n",
    "                    watch=False)\n",
    "    except:\n",
    "        print(\"There was an error, probably due to port closure. Trying again with the next port.\")\n",
    "        pt += 1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "animalaiv3.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
